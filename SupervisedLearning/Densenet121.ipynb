{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fd771e-2e61-4f68-8d7a-6ce4c2de7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from xy_dataset import XYDataset\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "from utils import preprocess\n",
    "import threading\n",
    "import time\n",
    "from utils import preprocess\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af4d3e2-0bfb-4936-9dbf-e72566654c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['apex']\n",
    "\n",
    "TRANSFORMS = transforms.Compose([\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = XYDataset(\"data_obstacle_detection/road_following_D\", CATEGORIES, TRANSFORMS, random_hflip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ba4b7a-3c8e-4f29-bce8-e7e409324359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaaibhavi Singh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Vaaibhavi Singh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7b3850016f4ebb8c07d4f6729ffe94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='road_following_model_densenet121.pth', description='model path'), HBox(children=(Bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#device = torch.device('cuda')\n",
    "device = torch.device('cpu')\n",
    "output_dim = 2 * len(dataset.categories)  # x, y coordinate for each category\n",
    "\n",
    "# DENSENET 121\n",
    "model = torchvision.models.densenet121(pretrained=True)\n",
    "model.classifier = torch.nn.Linear(1024, output_dim)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model_save_button = ipywidgets.Button(description='save model')\n",
    "model_load_button = ipywidgets.Button(description='load model')\n",
    "model_path_widget = ipywidgets.Text(description='model path', value='road_following_model_densenet121.pth')\n",
    "\n",
    "def load_model(c):\n",
    "    model.load_state_dict(torch.load(model_path_widget.value))\n",
    "model_load_button.on_click(load_model)\n",
    "    \n",
    "def save_model(c):\n",
    "    torch.save(model.state_dict(), model_path_widget.value)\n",
    "model_save_button.on_click(save_model)\n",
    "\n",
    "model_widget = ipywidgets.VBox([\n",
    "    model_path_widget,\n",
    "    ipywidgets.HBox([model_load_button, model_save_button])\n",
    "])\n",
    "\n",
    "display(model_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3256dd92-780c-4ed0-8dbd-2b6b9a74518d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ab98668ba34f299bce6340b07aeb26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntText(value=1, description='epochs'), FloatProgress(value=0.0, description='progress', max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "epochs_widget = ipywidgets.IntText(description='epochs', value=1)\n",
    "eval_button = ipywidgets.Button(description='evaluate')\n",
    "train_button = ipywidgets.Button(description='train')\n",
    "loss_widget = ipywidgets.FloatText(description='loss')\n",
    "progress_widget = ipywidgets.FloatProgress(min=0.0, max=1.0, description='progress')\n",
    "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
    "\n",
    "def train_eval(is_training):\n",
    "    global BATCH_SIZE, LEARNING_RATE, MOMENTUM, model, dataset, optimizer, eval_button, train_button, accuracy_widget, loss_widget, progress_widget, state_widget\n",
    "    \n",
    "    #try:\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    state_widget.value = 'stop'\n",
    "    train_button.disabled = True\n",
    "    eval_button.disabled = True\n",
    "    time.sleep(1)\n",
    "\n",
    "    if is_training:\n",
    "        model = model.train()\n",
    "    else:\n",
    "        model = model.eval()\n",
    "\n",
    "    while epochs_widget.value > 0:\n",
    "        i = 0\n",
    "        sum_loss = 0.0\n",
    "        error_count = 0.0\n",
    "        for images, category_idx, xy in iter(train_loader):\n",
    "            # send data to device\n",
    "            images = images.to(device)\n",
    "            xy = xy.to(device)\n",
    "\n",
    "            if is_training:\n",
    "                # zero gradients of parameters\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # execute model to get outputs\n",
    "            outputs = model(images)\n",
    "\n",
    "            # compute MSE loss over x, y coordinates for associated categories\n",
    "            loss = 0.0\n",
    "            for batch_idx, cat_idx in enumerate(list(category_idx.flatten())):\n",
    "                loss += torch.mean((outputs[batch_idx][2 * cat_idx:2 * cat_idx+2] - xy[batch_idx])**2)\n",
    "            loss /= len(category_idx)\n",
    "\n",
    "            if is_training:\n",
    "                # run backpropogation to accumulate gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # step optimizer to adjust parameters\n",
    "                optimizer.step()\n",
    "\n",
    "            # increment progress\n",
    "            count = len(category_idx.flatten())\n",
    "            i += count\n",
    "            sum_loss += float(loss)\n",
    "            progress_widget.value = i / len(dataset)\n",
    "            loss_widget.value = sum_loss / i\n",
    "                \n",
    "        if is_training:\n",
    "            epochs_widget.value = epochs_widget.value - 1\n",
    "        else:\n",
    "            break\n",
    "    #except Exception as e:\n",
    "     #   pass\n",
    "    model = model.eval()\n",
    "\n",
    "    train_button.disabled = False\n",
    "    eval_button.disabled = False\n",
    "    state_widget.value = 'live'\n",
    "    \n",
    "train_button.on_click(lambda c: train_eval(is_training=True))\n",
    "eval_button.on_click(lambda c: train_eval(is_training=False))\n",
    "    \n",
    "train_eval_widget = ipywidgets.VBox([\n",
    "    epochs_widget,\n",
    "    progress_widget,\n",
    "    loss_widget,\n",
    "    ipywidgets.HBox([train_button, eval_button])\n",
    "])\n",
    "\n",
    "display(train_eval_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1030ac2f-6270-4554-86e8-b48814b39f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a38d26-ab15-447b-b619-e1f68c326ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
